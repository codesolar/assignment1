# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z0LwnlnCyD0y_S2XqHJOYQuGYuipvq3j
"""

#used to work with arrays
import numpy as np
#used to import dataset
import pandas as pd
# used for plotting the dataset
import matplotlib.pyplot as plt
#used for largest value 
import sys
#used for random values
import random

##google drive link of dataset 
url="https://drive.google.com/file/d/1vOxV1dIc0JKOu--I9g8ufQ7D3iBaD01_/view?usp=sharing"
url='https://drive.google.com/uc?id=' + url.split('/')[-2]

#used the dataset url to import dataset
dataframe=pd.read_csv(url,names=["X1","X2"])
print("data set")
print(dataframe.head())
#transposing the data frame and storing it in X.
X=dataframe.T

#making X as a numpy array.
X=np.array(X)

#X dataframe has 2 features and 1000 data frames. “n”  is the number of data points and number of features are stored in “number_of_features”
n=len(X[0])
number_of_features=len(X)

#function for plotting the graph 
def plot(X):
  X1=[]
  X2=[]
  for i in range(len(X[0])):
    X1.append(X[0][i])
    X2.append(X[1][i])
  plt.figure(figsize=(10,10))
  plt.plot(X1,X2,'ro')
  plt.xlabel('1st feature')
  plt.ylabel('2nd feature')
  plt.grid()
  plt.legend(["Datapoints"])
  plt.title("Original Dataset")
  plt.show()
print("Original Dataset")
plot(X)

#initializing the cluster means 
def initialization(X,k):
  Z=[]
  for i in range(n):
    Z.append(0)
  mean=[]
  for i in range(len(X)):
    l=[]
    for j in range(k):
      l.append(0)
    mean.append(l)
  mean=np.array(mean,float)

  cluster_centers=np.random.randint(n, size=k)
  for j in range(len(cluster_centers)):
      mean[:,j]=X[:,cluster_centers[j]]


  #for each point ,we are taking the cluster center which is at minimum distance from it
  for i in range(n):
    x=X[:,i]
    min_dist=sys.maxsize;
    min_index=-1
    for j in range(k):
      mu=mean[:,j]
      x=np.array(x)
      mu=np.array(mu)
      dist=(np.dot((x-mu).T,(x-mu)))**0.5;
      if min_dist>dist:
        min_dist=dist
        min_index=j
    Z[i]=min_index
  return mean,Z

# error computation or objective value

def error(X,Z,mean):
  dist_sq=0
  for i in range(n):
    x=X[:,i]

    #computing distance of each component from its cluster's mean
    dist_sq+=np.dot((x-mean[:,Z[i]]).T,(x-mean[:,Z[i]]))
  return dist_sq

# mean computation steps

def mean_computation(X,Z,k):
  mean=[]
  for i in range(len(X)):
    l=[]
    for j in range(k):
      l.append(0)
    mean.append(l)
  mean=np.array(mean,float)

  #counting number of points in a cluster
  count=[]
  for i in range(k):
    count.append(0)

  #finding sum of all points in a cluster
  for i in range(n):
    count[Z[i]]+=1
    mean[:,Z[i]]=mean[:,Z[i]]+X[:,i]

  #finding mean of each cluster
  index=[]
  for i in range(k):
    if count[i]!=0:
      mean[:,i]=mean[:,i]/count[i]
    else:
      index.append(i)
  
  #deleting the mean point which has no other point in its cluster
  for i in index:
    np.delete(mean,index, axis=1)

  
            
  return mean

#checking if the points go to another cluster or not. if it goes then assigning  it to that cluster
def reassign(X,mean,k):
  Z=[]
  for i in range(n):
    Z.append(0)

  #for every datapoint we are computing distance to all  means and we are assigning the point to that cluster whose mean is closest to that point
  for i in range(n):
    x=X[:,i]
    min_dist=sys.maxsize;
    min_index=-1
    for index in range(k):
      mu=mean[:,index]
      x=np.array(x)
      mu=np.array(mu)
      dist=(np.dot((x-mu).T,(x-mu))**0.5);
      if min_dist>dist:
        min_dist=dist
        min_index=index
    Z[i]=min_index
  return Z

#function for kmeans
def kmeans(X,k):
  error_list=[]

  #initializing the datapoints and the means 
  mean,Z=initialization(X,k)


  #run a loop till no change  happens in the assignments of the clusters
  changes=True
  error_val=0
  while(changes):

    #initializes the clusters and finds the mean of the datapoints 
    mean=mean_computation(X,Z,k)
    error_val=error(X,Z,mean)
    error_list.append(error_val)

    #reassign the datapoints into new clusters if it is possible  
    Z_new=reassign(X,mean,k)
    flag=False
    for i in range(len(Z_new)):
      if(Z[i]!=Z_new[i]):
        flag=True
        break
    if flag==True:
      changes=True
    else: changes=False
    Z=Z_new
  return error_list,Z,mean

print("1st question")

#doing random initialization 5 times and also plotting the error values, so in total loop runs 10 times.when loop number is even(loop number starts from 0),then 
#print the graph with cluster assignments , otherwise print the error value with respect to the iteration number

k=4
fig,axs=plt.subplots(10,figsize=(10,100))
color=["brown","red","blue","green","yellow"]
for i in range(10):

#for the graph with clustering
  if i%2==0:

    #kmeans algo run
    error_list,Z,mean=kmeans(X,k)

    #seperating features of the mean points 
    x1=[]
    x2=[]
    for j in range(len(mean[0])):
      x1.append(mean[0][j])
      x2.append(mean[1][j])
  
    #plotting the points
    axs[i].scatter(x1,x2,color='black')


    #color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
    color_mat=[]
    for j in range(k):
      mat=[-1]
      color_mat.append(mat)
    for j in range(n):
      color_mat[Z[j]].append(j)

    #seperating features of the data points
    X3=[]
    X4=[]
    for j in range(len(X[0])):
      X3.append(X[0][j])
      X4.append(X[1][j])

    #for each cluster ,store the two features of all points lying in that cluster and plot those points
    for j in range(k):
      x=[]
      y=[]
      for l in range(1,len(color_mat[j])):
        x.append(X3[color_mat[j][l]])
        y.append(X4[color_mat[j][l]])
      axs[i].scatter(x,y,color=color[j])
    legend_string=["mean","cluster 1","cluster 2","cluster 3","cluster 4"]

    axs[i].legend(legend_string)
    axs[i].grid(True)
    axs[i].set_xlabel("1st feature")
    axs[i].set_ylabel("2nd feature")
    axs[i].set_title("After Clustering")

#for the error with iteration number
  else:
    iterations=np.arange(1,len(error_list)+1,1)
    axs[i].plot(iterations,error_list)
    axs[i].set_xlabel("iteration number")
    axs[i].set_ylabel("error")
    axs[i].set_title("error-vs-iteration number")
    axs[i].grid(True)

print("2nd question")

import seaborn as sns
#running for cluster number  of 2, 3, 4, 5, but with fixed initialization
K_list=[2,3,4,5]
count=0

#randomly assigning all points 
start_Z=np.random.randint(n, size=n)

#for every k value run the loop
for k in K_list:
  Z=[]
  
  plt.figure(figsize=(9,9)) 
  #for every datapoint run the loop and assign that point to some cluster
  for i in range(n):
    Z.append(start_Z[i] % k)
  Z=np.array(Z)


  error_list=[]
  mean=[]
  changes=True
  error_val=0

  #run till changes happen
  while(changes): 

    #compute the mean of each cluster
    mean=mean_computation(X,Z,k)

    #compute the error value in that cluster
    error_val=error(X,Z,mean)
    error_list.append(error_val)

    #check if reassignment happens , if it happens then reassign it
    Z_new=reassign(X,mean,k)
    flag=False
    for i in range(len(Z_new)):
      if(Z[i]!=Z_new[i]):
        flag=True
        break
    if flag==True:
      changes=True
    else: changes=False
    Z=Z_new

  #seperating features of the mean points
  x1=[]
  x2=[]
  for i in range(len(mean[0])):
    x1.append(mean[0][i])
    x2.append(mean[1][i])
  
  plt.scatter(x1,x2,color='black')



  x_array=np.arange(-10, 10, 0.5, dtype=float)
  y_array=np.arange(-10, 10, 0.5, dtype=float)
  znew=[]
  xx=[]
  yy=[]
  for ii in range(len(x_array)):
    for jj in range(len(y_array)):
      min_dist=sys.maxsize
      index=0
      sum=0
      for kk in range(len(mean[0])):
        dist=(x_array[ii]-mean[0][kk])**2 +(y_array[jj]-mean[1][kk])**2
        if(min_dist>dist):
          index=kk
          min_dist=dist
      xx.append(x_array[ii])
      yy.append(y_array[jj])
      znew.append(index)



  Data = {"1st_feature":xx,"2nd_feature":yy,"voronoi points":znew}

  sns.scatterplot(data=Data,x="1st_feature",y="2nd_feature",hue="voronoi points")
  
  #color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
  color_mat=[]
  for i in range(k):
    mat=[-1]
    color_mat.append(mat)
  for i in range(n):
    color_mat[Z[i]].append(i)


  #seperating features of the data points
  X3=[]
  X4=[]
  for i in range(len(X[0])):
    X3.append(X[0][i])
    X4.append(X[1][i])


  #for each cluster ,store the two features of all points lying in that cluster and plot those points
  for i in range(k):
    x=[]
    y=[]
    for j in range(1,len(color_mat[i])):
      x.append(X3[color_mat[i][j]])
      y.append(X4[color_mat[i][j]])
    plt.scatter(x,y)
  plt.grid(True)
  plt.xlabel("1st_feature")
  plt.ylabel("2nd_feature")
  plt.title("PLotting of voronoi region for k={}".format(k))
  plt.show()

print("3rd question")

#code for making kernel matrix
def poly_kernel(X,d):
  kernel_matrix=[]
  for i in range(len(X[0])):
    l=[]
    for j in range(len(X[0])):
      x=[]
      y=[]
      x.append(X[0][i])
      x.append(X[1][i])
      y.append(X[0][j])
      y.append(X[1][j])

      #using kernel function on the two vectors x and y
      ans=np.power((np.dot(x,y)+1),d)
      l.append(ans)
    kernel_matrix.append(l)
  return kernel_matrix

#kernel matrix centering part
def kernel_centering(kernel_matrix):
  one_n=[]
  for i in range(n):
    l=[]
    for j in range(n):
      l.append(1/n)
    one_n.append(l)

  kernel_centered=kernel_matrix-np.dot(one_n,kernel_matrix)-np.dot(kernel_matrix,one_n)+np.dot(np.dot(one_n,kernel_matrix),one_n)

  flag=True
  for i in range(n):
    for j in range(i+1,n):
      if kernel_centered[i][j]!=kernel_centered[j][i]:
        flag=False
        break

  return kernel_centered

#cluster number is k=4
k=4
plt.figure(figsize=(10,10)) 
#making kernel matrix with polynomial kernel of degree 2 
kernel_matrix=poly_kernel(X,2)

#centering the matrix
kernel_matrix=kernel_centering(kernel_matrix)

#finding eigen values an eigen vectors and sort the eigen values in decreasing order , sorting the eigen vectors in the same order
eigenvalues,betas=np.linalg.eigh(kernel_matrix)
order=np.argsort(eigenvalues,axis=0)[::-1]
eigenvalues=eigenvalues[order]
betas=betas[:,order]


#initializing H matrix
H=[]
for i in range(n):
  l=[]
  for j in range(k):
    l.append(0)
  H.append(l)

H=np.array(H,float)

#taking top k eigen vectors in the H matrix as columns
for i in range(k):
  H[:,i]=betas[:,i]

#taking rows of H as datapoints and transposing it ,to make the form of original dataset
data_in_higher_dim=H.T

#running k means 
error_list,Z,mean=kmeans(data_in_higher_dim,k)

#seperating x1 and x2 component of each datapoint
X1=[]
X2=[]
for i in range(len(X[0])):
  X1.append(X[0][i])
  X2.append(X[1][i])


##color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
color_mat=[]
for i in range(k):
  mat=[-1]
  color_mat.append(mat)
for i in range(n):
  color_mat[Z[i]].append(i)


##for each cluster ,store the two features of all points lying in that cluster and plot those points
for i in range(k):
    x=[]
    y=[]
    for j in range(1,len(color_mat[i])):
      x.append(X1[color_mat[i][j]])
      y.append(X2[color_mat[i][j]])
    plt.scatter(x,y)
    plt.xlabel("1st feature")
    plt.ylabel("2nd feature")
plt.grid(True)
legend_string=["cluster 1","cluster 2","cluster 3","cluster 4"]

plt.legend(legend_string)

plt.title("Polynomial Kernel Degree=2")
plt.show()

#cluster number is k=4
k=4
#making kernel matrix with polynomial kernel of degree 3
kernel_matrix=poly_kernel(X,2)

#centering the matrix
kernel_matrix=kernel_centering(kernel_matrix)

#finding eigen values an eigen vectors and sort the eigen values in decreasing order , sorting the eigen vectors in the same order
eigenvalues,betas=np.linalg.eigh(kernel_matrix)
order=np.argsort(eigenvalues,axis=0)[::-1]
eigenvalues=eigenvalues[order]
betas=betas[:,order]


#initializing H matrix
H=[]
for i in range(n):
  l=[]
  for j in range(k):
    l.append(0)
  H.append(l)

H=np.array(H,float)

#taking top k eigen vectors in the H matrix as columns
for i in range(k):
  H[:,i]=betas[:,i]


#taking rows of H as datapoints and transposing it ,to make the form of original dataset
data_in_higher_dim=H.T

#running k means
sum=0
for i in range(10):
  error_list,Z,mean=kmeans(data_in_higher_dim,k)
  sum=sum+error_list[-1]

print("error for polynomial kernel of degree =2==>{}".format(sum/10))

#cluster number is k=4
k=4
plt.figure(figsize=(10,10)) 
#making kernel matrix with polynomial kernel of degree 3
kernel_matrix=poly_kernel(X,3)

#centering the matrix
kernel_matrix=kernel_centering(kernel_matrix)

#finding eigen values an eigen vectors and sort the eigen values in decreasing order , sorting the eigen vectors in the same order
eigenvalues,betas=np.linalg.eigh(kernel_matrix)
order=np.argsort(eigenvalues,axis=0)[::-1]
eigenvalues=eigenvalues[order]
betas=betas[:,order]


#initializing H matrix
H=[]
for i in range(n):
  l=[]
  for j in range(k):
    l.append(0)
  H.append(l)

H=np.array(H,float)

#taking top k eigen vectors in the H matrix as columns
for i in range(k):
  H[:,i]=betas[:,i]


#taking rows of H as datapoints and transposing it ,to make the form of original dataset
data_in_higher_dim=H.T

#running k means 
error_list,Z,mean=kmeans(data_in_higher_dim,k)


#seperating x1 and x2 component of each datapoint
X1=[]
X2=[]
for i in range(len(X[0])):
  X1.append(X[0][i])
  X2.append(X[1][i])


##color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
color_mat=[]
for i in range(k):
  mat=[-1]
  color_mat.append(mat)
for i in range(n):
  color_mat[Z[i]].append(i)



##for each cluster ,store the two features of all points lying in that cluster and plot those points
for i in range(k):
    x=[]
    y=[]
    for j in range(1,len(color_mat[i])):
      x.append(X1[color_mat[i][j]])
      y.append(X2[color_mat[i][j]])
    plt.scatter(x,y)
    plt.xlabel("1st feature")
    plt.ylabel("2nd feature")
plt.grid(True)
legend_string=["cluster 1","cluster 2","cluster 3","cluster 4"]

plt.legend(legend_string)

plt.title("Polynomial Kernel Degree=3")
plt.show()

#cluster number is k=4
k=4
#making kernel matrix with polynomial kernel of degree 3
kernel_matrix=poly_kernel(X,3)

#centering the matrix
kernel_matrix=kernel_centering(kernel_matrix)

#finding eigen values an eigen vectors and sort the eigen values in decreasing order , sorting the eigen vectors in the same order
eigenvalues,betas=np.linalg.eigh(kernel_matrix)
order=np.argsort(eigenvalues,axis=0)[::-1]
eigenvalues=eigenvalues[order]
betas=betas[:,order]


#initializing H matrix
H=[]
for i in range(n):
  l=[]
  for j in range(k):
    l.append(0)
  H.append(l)

H=np.array(H,float)

#taking top k eigen vectors in the H matrix as columns
for i in range(k):
  H[:,i]=betas[:,i]


#taking rows of H as datapoints and transposing it ,to make the form of original dataset
data_in_higher_dim=H.T

#running k means
sum=0
for i in range(10):
  error_list,Z,mean=kmeans(data_in_higher_dim,k)
  sum=sum+error_list[-1]

print("error corresponding to polynomial degree 3 ==>{}".format(sum/10))

#sigma values in a list
sigmas=np.arange(0.1,1.1,0.1)
sigmas=tuple(sigmas)

#kmeans with RBF
fig,axs=plt.subplots(5,2,figsize=(20,50))
index=0
for ii in range(5):
  for jj in range(2):
    sigma=sigmas[index]
    index+=1
    kernel_matrix=[]
    sigma_squared=sigma**2

    #code for making kernel matrix
    for p in range(len(X[0])):
      l=[]
      for q in range(len(X[0])):
        x=[]
        y=[]
        x.append(X[0][p])
        x.append(X[1][p])
        y.append(X[0][q])
        y.append(X[1][q])
        x=np.array(x)
        y=np.array(y)
        ans=np.exp(-np.dot((x-y).T,(x-y))/(2*sigma_squared))
        l.append(ans)
      kernel_matrix.append(l)

    #kernel centering part
    one_n=[]
    for p in range(n):
      l=[]
      for q in range(n):
        l.append(1/n)
      one_n.append(l)
    kernel_centered=kernel_matrix-np.dot(one_n,kernel_matrix)-np.dot(kernel_matrix,one_n)+np.dot(np.dot(one_n,kernel_matrix),one_n)
    kernel_matrix=kernel_centered  

    #eigen values and eigen vectors for kernel matrix
    eigenvalues,betas=np.linalg.eigh(kernel_matrix)
    order=np.argsort(eigenvalues,axis=0)[::-1]
    eigenvalues=eigenvalues[order]
    betas=betas[:,order]


    #initializing the H matrix
    H=[]
    for i in range(n):
      l=[]
      for j in range(k):
        l.append(0)
      H.append(l)

    H=np.array(H,float)

    #taking top k eigen vectors in the H matrix as columns
    for i in range(k):
      H[:,i]=betas[:,i]


    #taking rows of H as datapoints and transposing it ,to make the form of original dataset
    data_in_higher_dim=H.T

    #running k means 
    error_list,Z,mean=kmeans(data_in_higher_dim,k)

    #seperating x1 and x2 component of each datapoint
    X1=[]
    X2=[]
    for i in range(len(X[0])):
      X1.append(X[0][i])
      X2.append(X[1][i])


    ##color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
    color_mat=[]
    for i in range(k):
      mat=[-1]
      color_mat.append(mat)
    for i in range(n):
      color_mat[Z[i]].append(i)


    ##for each cluster ,store the two features of all points lying in that cluster and plot those points
    for i in range(k):
        x=[]
        y=[]
        for j in range(1,len(color_mat[i])):
          x.append(X1[color_mat[i][j]])
          y.append(X2[color_mat[i][j]])
        axs[ii][jj].scatter(x,y)
        axs[ii][jj].set_title("RBF Kernel with sigma={:.1f}".format(sigma))
        axs[ii][jj].set_xlabel("1st feature")
        axs[ii][jj].set_ylabel("2nd feature")
    axs[ii][jj].grid(True)
    legend_string=["cluster 1","cluster 2","cluster 3","cluster 4"]

    axs[ii][jj].legend(legend_string)

for ii in range(len(sigmas)):
  #cluster number is k=4
  k=4
  #making kernel matrix with polynomial kernel of degree 3
  kernel_matrix=[]


  sigma=sigmas[ii]
  kernel_matrix=[]
  sigma_squared=sigma**2

  #code for making kernel matrix
  for p in range(len(X[0])):
    l=[]
    for q in range(len(X[0])):
      x=[]
      y=[]
      x.append(X[0][p])
      x.append(X[1][p])
      y.append(X[0][q])
      y.append(X[1][q])
      x=np.array(x)
      y=np.array(y)
      ans=np.exp(-np.dot((x-y).T,(x-y))/(2*sigma_squared))
      l.append(ans)
    kernel_matrix.append(l)
  # centering the matrix
  kernel_matrix=kernel_centering(kernel_matrix)
  

  #finding eigen values an eigen vectors and sort the eigen values in decreasing order , sorting the eigen vectors in the same order
  eigenvalues,betas=np.linalg.eigh(kernel_matrix)
  order=np.argsort(eigenvalues,axis=0)[::-1]
  eigenvalues=eigenvalues[order]
  betas=betas[:,order]


  #initializing H matrix
  H=[]
  for i in range(n):
    l=[]
    for j in range(k):
      l.append(0)
    H.append(l)

  H=np.array(H,float)

  #taking top k eigen vectors in the H matrix as columns
  for i in range(k):
    H[:,i]=betas[:,i]


  #taking rows of H as datapoints and transposing it ,to make the form of original dataset
  data_in_higher_dim=H.T

  #running k means
  sum=0
  for i in range(10):
    error_list,Z,mean=kmeans(data_in_higher_dim,k)
    sum=sum+error_list[-1]
  print("sigma={:.1f}".format(sigma))
  print("error value corresponding to this sigma ={}".format(sum/10))

#kernel_matrix creation
kernel_matrix=poly_kernel(X,2)

#kernel_matrix centering
kernel_matrix=kernel_centering(kernel_matrix)

#eigenvalues and eigen vcetors finding
eigenvalues,betas=np.linalg.eigh(kernel_matrix)
k=4

#sorting eigen values and eigen vectors according to eigen values decreasing order. taking eigen vectors in that order
order=np.argsort(eigenvalues,axis=0)[::-1]
eigenvalues=eigenvalues[order]
betas=betas[:,order]

#initializing H matrix
H=[]
for i in range(n):
  l=[]
  for j in range(k):
    l.append(0)
  H.append(l)

H=np.array(H,float)

#taking top k eigen vectors in the H matrix as columns
for i in range(k):
  H[:,i]=betas[:,i]

#taking maximum value's index in each row and that number would be cluster number
for i in range(n):
  max=H[i,0]
  for j in range(1,k):
    if H[i,j]>max:
      max=H[i,j]
  for j in range(k):
    if max==H[i,j]:
      H[i,j]=1
    else: H[i,j]=0

#storing the features of all points
X1=[]
X2=[]
for i in range(len(X[0])):
  X1.append(X[0][i])
  X2.append(X[1][i])


#creating Z matrix from H matrix
Z=[]
for i in range(n):
  for j in range(k):
    if H[i,j]==1:
      Z.append(j)
      break
np.array(Z)
##color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
color_mat=[]
for i in range(k):
  mat=[-1]
  color_mat.append(mat)
for i in range(n):
  index=0
  for j in range(k):
    if H[i,j]==1:
      index=j
      break
  color_mat[index].append(i)

plt.figure(figsize=(10,10)) 
##for each cluster ,store the two features of all points lying in that cluster and plot those points
for i in range(k):
    x=[]
    y=[]
    for j in range(1,len(color_mat[i])):
      x.append(X1[color_mat[i][j]])
      y.append(X2[color_mat[i][j]])
    plt.scatter(x,y)
plt.xlabel("1st feature")
plt.ylabel("2nd feature")
plt.grid(True)
legend_string=["cluster 1","cluster 2","cluster 3","cluster 4"]
plt.legend(legend_string)

plt.title("Polynomial Kernel Degree=2")

mean=mean_computation(X,Z,4)
err=error(X,Z,mean)
print("error of polynomial degree=2=={}".format(err))

#  kernel_matrix=[]
#kernel_matrix creation
kernel_matrix=poly_kernel(X,3)

#kernel_matrix centering
kernel_matrix=kernel_centering(kernel_matrix)
#eigenvalues and eigen vcetors finding
eigenvalues,betas=np.linalg.eigh(kernel_matrix)
k=4
#sorting eigen values and eigen vectors according to eigen values decreasing order. taking eigen vectors in that order
order=np.argsort(eigenvalues,axis=0)[::-1]
eigenvalues=eigenvalues[order]
betas=betas[:,order]

#initializing H matrix
H=[]
for i in range(n):
  l=[]
  for j in range(k):
    l.append(0)
  H.append(l)

H=np.array(H,float)
#taking top k eigen vectors in the H matrix as columns
for i in range(k):
  H[:,i]=betas[:,i]


#taking maximum value's index in each row and that number would be cluster number
for i in range(n):
  max=H[i,0]
  for j in range(1,k):
    if H[i,j]>max:
      max=H[i,j]
  for j in range(k):
    if max==H[i,j]:
      H[i,j]=1
    else: H[i,j]=0



#storing the features of all points
X1=[]
X2=[]
for i in range(len(X[0])):
  X1.append(X[0][i])
  X2.append(X[1][i])



#creating Z matrix from H matrix
Z=[]
for i in range(n):
  for j in range(k):
    if H[i,j]==1:
      Z.append(j)
      break
np.array(Z)


##color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
color_mat=[]
for i in range(k):
  mat=[-1]
  color_mat.append(mat)
for i in range(n):
  index=0
  for j in range(k):
    if H[i,j]==1:
      index=j
      break
  color_mat[index].append(i)



plt.figure(figsize=(10,10)) 
##for each cluster ,store the two features of all points lying in that cluster and plot those points
for i in range(k):
    x=[]
    y=[]
    for j in range(1,len(color_mat[i])):
      x.append(X1[color_mat[i][j]])
      y.append(X2[color_mat[i][j]])
    plt.scatter(x,y)
plt.xlabel("1st feature")
plt.ylabel("2nd feature")
plt.grid(True)
legend_string=["cluster 1","cluster 2","cluster 3","cluster 4"]
plt.legend(legend_string)

plt.title("Polynomial Kernel Degree=3")

mean=mean_computation(X,Z,4)
err=error(X,Z,mean)
print("error of polynomial degree=3==>{}".format(err))

#list of sigma values for doing rbf 
sigmas=np.arange(0.1,1.1,0.1)
sigmas=tuple(sigmas)

#making subplots
fig,axs=plt.subplots(5,2,figsize=(20,50))
index=0
for ii in range(5):
  for jj in range(2):

    #taking one sigma from the list of sigmas
    sigma=sigmas[index]
    index+=1

    #kernel matrix creation
    kernel_matrix=[]
    sigma_squared=sigma**2
    for p in range(len(X[0])):
      l=[]
      for q in range(len(X[0])):
        x=[]
        y=[]
        x.append(X[0][p])
        x.append(X[1][p])
        y.append(X[0][q])
        y.append(X[1][q])
        x=np.array(x)
        y=np.array(y)
        ans=np.exp(-np.dot((x-y).T,(x-y))/(2*sigma_squared))
        l.append(ans)
      kernel_matrix.append(l)

    #creation of one_n matrix
    one_n=[]
    for p in range(n):
      l=[]
      for q in range(n):
        l.append(1/n)
      one_n.append(l)

    #kernel matrix centering
    kernel_centered=kernel_matrix-np.dot(one_n,kernel_matrix)-np.dot(kernel_matrix,one_n)+np.dot(np.dot(one_n,kernel_matrix),one_n)
    kernel_matrix=kernel_centered  

    #finding eigen value  and eigen vector of kernel _matrix
    eigenvalues,betas=np.linalg.eigh(kernel_matrix)

    #sorting eigen values and eigen vectors according to eigen values decreasing order. taking eigen vectors in that order
    order=np.argsort(eigenvalues,axis=0)[::-1]
    eigenvalues=eigenvalues[order]
    betas=betas[:,order]

    #initializing H matrix
    H=[]
    for i in range(n):
      l=[]
      for j in range(k):
        l.append(0)
      H.append(l)

    H=np.array(H,float)
    #taking top k eigen vectors in the H matrix as columns
    for i in range(k):
      H[:,i]=betas[:,i]

    #taking maximum value's index in each row and that number would be cluster number
    for i in range(n):
      max=H[i,0]
      for j in range(1,k):
        if H[i,j]>max:
          max=H[i,j]
      for j in range(k):
        if max==H[i,j]:
          H[i,j]=1
        else: H[i,j]=0



    #storing the features of all points
    X1=[]
    X2=[]
    for i in range(len(X[0])):
      X1.append(X[0][i])
      X2.append(X[1][i])


    #creating Z matrix from H matrix
    Z=[]
    for i in range(n):
      for j in range(k):
        if H[i,j]==1:
          Z.append(j)
          break
    np.array(Z)

    mean=mean_computation(X,Z,4)
    err=error(X,Z,mean)
    print("sigma={:.1f}".format(sigma))
    print("error corresponding to this sigma ={}".format(err))
    #color_mat is a matrix in which the i-th row stores the indices of the datapoints which go to cluster i
    color_mat=[]
    for i in range(k):
      mat=[-1]
      color_mat.append(mat)
    for i in range(n):
      indexx=0
      for j in range(k):
        if H[i,j]==1:
          indexx=j
          break
      color_mat[indexx].append(i)


    #for each cluster ,store the two features of all points lying in that cluster and plot those points
    for i in range(k):
        x=[]
        y=[]
        for j in range(1,len(color_mat[i])):
          x.append(X1[color_mat[i][j]])
          y.append(X2[color_mat[i][j]])
        axs[ii][jj].scatter(x,y)
    axs[ii][jj].set_xlabel("1st feature")
    axs[ii][jj].set_ylabel("2nd feature")
    axs[ii][jj].grid(True)
    legend_string=["cluster 1","cluster 2","cluster 3","cluster 4"]
    axs[ii][jj].legend(legend_string)

    axs[ii][jj].set_title("RBF Kernel sigma={: 0.1f}".format(sigma))